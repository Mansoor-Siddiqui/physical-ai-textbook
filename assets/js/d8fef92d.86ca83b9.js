"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[429],{4913(r,n,e){e.r(n),e.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"isaac-sim/index","title":"NVIDIA Isaac Sim","description":"Master NVIDIA\'s powerful robotics simulation platform for AI development","source":"@site/docs/isaac-sim/index.md","sourceDirName":"isaac-sim","slug":"/isaac-sim/","permalink":"/physical-ai-textbook/docs/isaac-sim/","draft":false,"unlisted":false,"editUrl":"https://github.com/Mansoor-Siddiqui/physical-ai-textbook/tree/master/physical-ai-textbook/docs/isaac-sim/index.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"NVIDIA Isaac Sim","description":"Master NVIDIA\'s powerful robotics simulation platform for AI development","keywords":["nvidia","isaac sim","omniverse","synthetic data","digital twin","simulation"]},"sidebar":"textbookSidebar","previous":{"title":"Robot Simulation","permalink":"/physical-ai-textbook/docs/simulation/"},"next":{"title":"Vision-Language-Action Models","permalink":"/physical-ai-textbook/docs/vla-models/"}}');var t=e(4848),a=e(8453),o=e(5168);const s={sidebar_position:4,title:"NVIDIA Isaac Sim",description:"Master NVIDIA's powerful robotics simulation platform for AI development",keywords:["nvidia","isaac sim","omniverse","synthetic data","digital twin","simulation"]},l="NVIDIA Isaac Sim",d={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"What is Isaac Sim?",id:"what-is-isaac-sim",level:2},{value:"Key Features",id:"key-features",level:3},{value:"Isaac Sim Architecture",id:"isaac-sim-architecture",level:3},{value:"Getting Started",id:"getting-started",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation",id:"installation",level:3},{value:"First Steps in Isaac Sim",id:"first-steps-in-isaac-sim",level:3},{value:"Working with Robots",id:"working-with-robots",level:2},{value:"Importing URDF",id:"importing-urdf",level:3},{value:"Robot Controller",id:"robot-controller",level:3},{value:"Differential Drive Robot",id:"differential-drive-robot",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:2},{value:"Camera Sensor",id:"camera-sensor",level:3},{value:"LiDAR Sensor",id:"lidar-sensor",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Basic Replicator Setup",id:"basic-replicator-setup",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Training Data for Object Detection",id:"training-data-for-object-detection",level:3},{value:"ROS2 Integration",id:"ros2-integration",level:2},{value:"Isaac Sim ROS2 Bridge",id:"isaac-sim-ros2-bridge",level:3},{value:"Action Graph for ROS2",id:"action-graph-for-ros2",level:3},{value:"Headless Training",id:"headless-training",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(r){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...r.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"nvidia-isaac-sim",children:"NVIDIA Isaac Sim"})}),"\n",(0,t.jsxs)("div",{className:"learning-objectives",children:[(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),(0,t.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand Isaac Sim's architecture and capabilities"}),"\n",(0,t.jsx)(n.li,{children:"Set up and navigate the Isaac Sim environment"}),"\n",(0,t.jsx)(n.li,{children:"Import and configure robot models in Isaac Sim"}),"\n",(0,t.jsx)(n.li,{children:"Generate synthetic training data for AI models"}),"\n",(0,t.jsx)(n.li,{children:"Create digital twin workflows for robot development"}),"\n",(0,t.jsx)(n.li,{children:"Integrate Isaac Sim with ROS2"}),"\n"]})]}),"\n",(0,t.jsx)(n.h2,{id:"what-is-isaac-sim",children:"What is Isaac Sim?"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"NVIDIA Isaac Sim"})," is a robotics simulation platform built on NVIDIA Omniverse. It provides photorealistic rendering, accurate physics simulation, and powerful tools for developing, testing, and training AI-based robots."]}),"\n",(0,t.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Feature"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Photorealistic Rendering"})}),(0,t.jsx)(n.td,{children:"RTX ray tracing for realistic visuals and sensor simulation"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"PhysX 5 Physics"})}),(0,t.jsx)(n.td,{children:"Accurate rigid body, articulation, and soft body simulation"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Synthetic Data Generation"})}),(0,t.jsx)(n.td,{children:"Automated ground truth labeling for training data"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Domain Randomization"})}),(0,t.jsx)(n.td,{children:"Vary environments for robust sim-to-real transfer"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"ROS2 Integration"})}),(0,t.jsx)(n.td,{children:"Native bridges to ROS2 ecosystem"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Python API"})}),(0,t.jsx)(n.td,{children:"Full scriptability for automation and training"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Cloud Scalability"})}),(0,t.jsx)(n.td,{children:"Run thousands of simulations in parallel"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"isaac-sim-architecture",children:"Isaac Sim Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                      NVIDIA ISAAC SIM                            \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                                                                  \u2502\r\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502   \u2502                    OMNIVERSE PLATFORM                     \u2502  \u2502\r\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\r\n\u2502   \u2502  \u2502    USD      \u2502  \u2502   Nucleus   \u2502  \u2502   Connectors    \u2502   \u2502  \u2502\r\n\u2502   \u2502  \u2502   Format    \u2502  \u2502   Database  \u2502  \u2502   (CAD/DCC)     \u2502   \u2502  \u2502\r\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\r\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502   \u2502   RTX        \u2502  \u2502   PhysX 5    \u2502  \u2502    Isaac           \u2502  \u2502\r\n\u2502   \u2502   Renderer   \u2502  \u2502   Physics    \u2502  \u2502    Extensions      \u2502  \u2502\r\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502   \u2502                    PYTHON API                             \u2502  \u2502\r\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\r\n\u2502   \u2502  \u2502 omni.isaac  \u2502  \u2502   Replicator \u2502  \u2502   ROS2 Bridge   \u2502   \u2502  \u2502\r\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\r\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502                                                                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,t.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Component"}),(0,t.jsx)(n.th,{children:"Minimum"}),(0,t.jsx)(n.th,{children:"Recommended"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"GPU"})}),(0,t.jsx)(n.td,{children:"RTX 2070"}),(0,t.jsx)(n.td,{children:"RTX 4080 or better"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"VRAM"})}),(0,t.jsx)(n.td,{children:"8 GB"}),(0,t.jsx)(n.td,{children:"16+ GB"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"RAM"})}),(0,t.jsx)(n.td,{children:"32 GB"}),(0,t.jsx)(n.td,{children:"64 GB"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Storage"})}),(0,t.jsx)(n.td,{children:"50 GB SSD"}),(0,t.jsx)(n.td,{children:"100+ GB NVMe"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"OS"})}),(0,t.jsx)(n.td,{children:"Ubuntu 20.04/22.04, Windows 10/11"}),(0,t.jsx)(n.td,{children:"Ubuntu 22.04"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Driver"})}),(0,t.jsx)(n.td,{children:"525.60+"}),(0,t.jsx)(n.td,{children:"Latest"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# 1. Install NVIDIA Omniverse Launcher\r\n# Download from: https://www.nvidia.com/omniverse\r\n\r\n# 2. Install Isaac Sim through the Launcher\r\n# Navigate to Exchange > Isaac Sim > Install\r\n\r\n# 3. Launch Isaac Sim\r\n# Or from terminal:\r\n~/.local/share/ov/pkg/isaac_sim-*/isaac-sim.sh\n"})}),"\n",(0,t.jsx)(n.h3,{id:"first-steps-in-isaac-sim",children:"First Steps in Isaac Sim"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# hello_isaac.py - Basic Isaac Sim script\r\nfrom omni.isaac.kit import SimulationApp\r\n\r\n# Initialize the simulation\r\nsimulation_app = SimulationApp({"headless": False})\r\n\r\n# Import after SimulationApp is created\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.objects import DynamicCuboid\r\nimport numpy as np\r\n\r\n# Create a world\r\nworld = World(stage_units_in_meters=1.0)\r\n\r\n# Add ground plane\r\nworld.scene.add_default_ground_plane()\r\n\r\n# Add a cube\r\ncube = world.scene.add(\r\n    DynamicCuboid(\r\n        prim_path="/World/Cube",\r\n        name="my_cube",\r\n        position=np.array([0.0, 0.0, 1.0]),\r\n        size=np.array([0.5, 0.5, 0.5]),\r\n        color=np.array([0.2, 0.4, 0.8])\r\n    )\r\n)\r\n\r\n# Reset the world\r\nworld.reset()\r\n\r\n# Run simulation loop\r\nwhile simulation_app.is_running():\r\n    world.step(render=True)\r\n    \r\n    # Get cube position\r\n    position, _ = cube.get_world_pose()\r\n    if position[2] < 0.3:  # Cube has fallen\r\n        print(f"Cube at rest: {position}")\r\n        break\r\n\r\nsimulation_app.close()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"working-with-robots",children:"Working with Robots"}),"\n",(0,t.jsx)(n.h3,{id:"importing-urdf",children:"Importing URDF"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core.utils.extensions import enable_extension\r\nenable_extension("omni.importer.urdf")\r\n\r\nfrom omni.importer.urdf import _urdf\r\nfrom omni.isaac.core import World\r\n\r\n# Configure URDF import\r\nurdf_interface = _urdf.acquire_urdf_interface()\r\n\r\nimport_config = _urdf.ImportConfig()\r\nimport_config.merge_fixed_joints = False\r\nimport_config.fix_base = False\r\nimport_config.import_inertia_tensor = True\r\nimport_config.distance_scale = 1.0\r\nimport_config.density = 0.0\r\nimport_config.default_drive_type = _urdf.UrdfJointTargetType.JOINT_DRIVE_POSITION\r\nimport_config.default_drive_strength = 1000.0\r\nimport_config.default_position_drive_damping = 100.0\r\n\r\n# Import the robot\r\nresult, robot_prim_path = urdf_interface.parse_urdf(\r\n    urdf_path="/path/to/robot.urdf",\r\n    import_config=import_config\r\n)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"robot-controller",children:"Robot Controller"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core.articulations import Articulation\r\nfrom omni.isaac.core.controllers import BaseController\r\nimport numpy as np\r\n\r\nclass SimpleArmController(BaseController):\r\n    def __init__(self, name: str, robot: Articulation):\r\n        super().__init__(name)\r\n        self._robot = robot\r\n        \r\n    def forward(self, target_positions: np.ndarray) -> np.ndarray:\r\n        """Compute joint actions to reach target positions"""\r\n        current_positions = self._robot.get_joint_positions()\r\n        \r\n        # Simple P controller\r\n        kp = 10.0\r\n        position_error = target_positions - current_positions\r\n        actions = kp * position_error\r\n        \r\n        return actions\r\n\r\n# Usage\r\nworld = World()\r\nrobot = world.scene.add(\r\n    Articulation(\r\n        prim_path="/World/Robot",\r\n        name="my_robot"\r\n    )\r\n)\r\n\r\ncontroller = SimpleArmController("arm_controller", robot)\r\n\r\n# In simulation loop\r\ntarget = np.array([0.0, 0.5, -0.5, 0.0, 0.0, 0.0])\r\nactions = controller.forward(target)\r\nrobot.apply_action(actions)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"differential-drive-robot",children:"Differential Drive Robot"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.wheeled_robots.robots import WheeledRobot\r\nfrom omni.isaac.wheeled_robots.controllers import DifferentialController\r\n\r\n# Create wheeled robot\r\nrobot = WheeledRobot(\r\n    prim_path="/World/Robot",\r\n    name="diff_drive_robot",\r\n    wheel_dof_names=["left_wheel_joint", "right_wheel_joint"],\r\n    create_robot=True,\r\n    usd_path="/path/to/robot.usd",\r\n    position=np.array([0.0, 0.0, 0.0])\r\n)\r\n\r\n# Create controller\r\ncontroller = DifferentialController(\r\n    name="diff_controller",\r\n    wheel_radius=0.05,\r\n    wheel_base=0.3\r\n)\r\n\r\n# Control with linear and angular velocity\r\nlinear_velocity = 0.5  # m/s\r\nangular_velocity = 0.2  # rad/s\r\n\r\nwheel_velocities = controller.forward(\r\n    command=[linear_velocity, angular_velocity]\r\n)\r\nrobot.apply_wheel_actions(wheel_velocities)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,t.jsx)(n.h3,{id:"camera-sensor",children:"Camera Sensor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\r\nimport numpy as np\r\n\r\n# Create camera\r\ncamera = Camera(\r\n    prim_path="/World/Robot/Camera",\r\n    name="front_camera",\r\n    frequency=30,\r\n    resolution=(640, 480),\r\n    position=np.array([0.5, 0.0, 0.3]),\r\n    orientation=np.array([1.0, 0.0, 0.0, 0.0])  # quaternion\r\n)\r\n\r\n# Initialize camera\r\ncamera.initialize()\r\n\r\n# Get RGB image\r\nrgb_data = camera.get_rgba()[:, :, :3]  # Remove alpha channel\r\n\r\n# Get depth\r\ndepth_data = camera.get_depth()\r\n\r\n# Get semantic segmentation (requires Replicator setup)\r\nsemantic_data = camera.get_semantic_segmentation()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"lidar-sensor",children:"LiDAR Sensor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.range_sensor import LidarRtx\r\n\r\n# Create LiDAR\r\nlidar = LidarRtx(\r\n    prim_path="/World/Robot/Lidar",\r\n    name="top_lidar",\r\n    position=np.array([0.0, 0.0, 0.5]),\r\n    rotation=np.array([0.0, 0.0, 0.0]),\r\n    config_file_path="/Isaac/Sensors/LiDAR/Velodyne_VLP16.json"\r\n)\r\n\r\n# Get point cloud\r\npoint_cloud = lidar.get_point_cloud()\r\n\r\n# Get range data\r\nranges = lidar.get_linear_depth_data()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,t.jsxs)(n.p,{children:["Isaac Sim's ",(0,t.jsx)(n.strong,{children:"Replicator"})," enables automated synthetic data generation with perfect ground truth labels."]}),"\n",(0,t.jsx)(n.h3,{id:"basic-replicator-setup",children:"Basic Replicator Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni.replicator.core as rep\r\n\r\n# Create a simple scene\r\nwith rep.new_layer():\r\n    # Create camera\r\n    camera = rep.create.camera(\r\n        position=(5, 5, 5),\r\n        look_at=(0, 0, 0)\r\n    )\r\n    \r\n    # Create render product\r\n    render_product = rep.create.render_product(camera, (1024, 1024))\r\n    \r\n    # Create writer for output\r\n    writer = rep.WriterRegistry.get("BasicWriter")\r\n    writer.initialize(\r\n        output_dir="_output",\r\n        rgb=True,\r\n        bounding_box_2d_tight=True,\r\n        semantic_segmentation=True,\r\n        instance_segmentation=True,\r\n        distance_to_camera=True\r\n    )\r\n    writer.attach([render_product])\r\n\r\n# Run data generation\r\nrep.orchestrator.run()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni.replicator.core as rep\r\n\r\ndef randomize_scene():\r\n    """Randomize scene for domain randomization"""\r\n    \r\n    # Randomize object positions\r\n    with rep.get.prims(semantics=[("class", "object")]):\r\n        rep.modify.pose(\r\n            position=rep.distribution.uniform((-2, -2, 0), (2, 2, 0.5)),\r\n            rotation=rep.distribution.uniform((0, 0, 0), (0, 0, 360))\r\n        )\r\n    \r\n    # Randomize lighting\r\n    with rep.get.prims(path_pattern="/World/Lights/*"):\r\n        rep.modify.attribute(\r\n            "intensity",\r\n            rep.distribution.uniform(500, 2000)\r\n        )\r\n        rep.modify.attribute(\r\n            "color",\r\n            rep.distribution.uniform((0.8, 0.8, 0.8), (1.0, 1.0, 1.0))\r\n        )\r\n    \r\n    # Randomize materials\r\n    with rep.get.prims(semantics=[("class", "floor")]):\r\n        rep.randomizer.materials(\r\n            materials=rep.get.material(path_pattern="/World/Materials/*")\r\n        )\r\n\r\n# Register randomizer\r\nrep.randomizer.register(randomize_scene)\r\n\r\n# Generate multiple frames with randomization\r\nwith rep.trigger.on_frame(num_frames=1000):\r\n    rep.randomizer.randomize_scene()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"training-data-for-object-detection",children:"Training Data for Object Detection"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni.replicator.core as rep\r\n\r\n# Scene setup\r\nwith rep.new_layer():\r\n    # Background\r\n    rep.create.plane(scale=10, material=rep.create.material_omnipbr(\r\n        diffuse_texture=rep.distribution.choice([\r\n            "omniverse://localhost/NVIDIA/Materials/Floor/concrete.mdl",\r\n            "omniverse://localhost/NVIDIA/Materials/Floor/wood.mdl",\r\n        ])\r\n    ))\r\n    \r\n    # Objects to detect\r\n    objects = []\r\n    for i in range(10):\r\n        obj = rep.create.from_usd(\r\n            rep.distribution.choice([\r\n                "/path/to/object1.usd",\r\n                "/path/to/object2.usd",\r\n                "/path/to/object3.usd",\r\n            ]),\r\n            semantics=[("class", "target_object")]\r\n        )\r\n        objects.append(obj)\r\n    \r\n    # Camera\r\n    camera = rep.create.camera(\r\n        position=rep.distribution.uniform((3, 3, 2), (5, 5, 4)),\r\n        look_at=(0, 0, 0)\r\n    )\r\n    \r\n    # Render product with annotations\r\n    rp = rep.create.render_product(camera, (1280, 720))\r\n    \r\n    # Writer with all annotations\r\n    writer = rep.WriterRegistry.get("KittiWriter")\r\n    writer.initialize(output_dir="_kitti_output")\r\n    writer.attach([rp])\r\n\r\n# Run with randomization\r\nwith rep.trigger.on_frame(num_frames=5000):\r\n    with rep.get.prims(semantics=[("class", "target_object")]):\r\n        rep.modify.pose(\r\n            position=rep.distribution.uniform((-2, -2, 0.1), (2, 2, 0.5)),\r\n            rotation=rep.distribution.uniform((0, 0, 0), (360, 360, 360))\r\n        )\n'})}),"\n",(0,t.jsx)(n.h2,{id:"ros2-integration",children:"ROS2 Integration"}),"\n",(0,t.jsx)(n.h3,{id:"isaac-sim-ros2-bridge",children:"Isaac Sim ROS2 Bridge"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core import World\r\nfrom omni.isaac.ros2_bridge import ROS2Bridge\r\nimport rclpy\r\n\r\n# Enable ROS2 bridge extension\r\nfrom omni.isaac.core.utils.extensions import enable_extension\r\nenable_extension("omni.isaac.ros2_bridge")\r\n\r\n# Create world\r\nworld = World()\r\n\r\n# Create robot and add to scene\r\n# ...\r\n\r\n# Initialize ROS2\r\nrclpy.init()\r\n\r\n# Camera publisher\r\nfrom omni.isaac.ros2_bridge import publishers\r\ncamera_publisher = publishers.CameraRgbPublisher(\r\n    camera_prim_path="/World/Robot/Camera",\r\n    topic_name="/camera/image_raw",\r\n    frame_id="camera_link"\r\n)\r\n\r\n# LiDAR publisher\r\nlidar_publisher = publishers.LaserScanPublisher(\r\n    lidar_prim_path="/World/Robot/Lidar",\r\n    topic_name="/scan",\r\n    frame_id="lidar_link"\r\n)\r\n\r\n# Command velocity subscriber\r\nfrom omni.isaac.ros2_bridge import subscribers\r\ncmd_vel_subscriber = subscribers.TwistSubscriber(\r\n    robot_prim_path="/World/Robot",\r\n    topic_name="/cmd_vel"\r\n)\r\n\r\n# Simulation loop\r\nwhile simulation_app.is_running():\r\n    world.step(render=True)\r\n    \r\n    # ROS2 communication happens automatically\r\n    rclpy.spin_once(timeout_sec=0)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"action-graph-for-ros2",children:"Action Graph for ROS2"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim uses Action Graphs for visual programming of ROS2 nodes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni.graph.core as og\r\n\r\n# Create action graph\r\nog.Controller.create_graph({\r\n    "graph_path": "/World/ROS2Graph",\r\n    "evaluator_name": "execution"\r\n})\r\n\r\n# Add ROS2 clock\r\nog.Controller.create_node(\r\n    "/World/ROS2Graph/ros2_clock",\r\n    "omni.isaac.ros2_bridge.ROS2Clock"\r\n)\r\n\r\n# Add camera publisher\r\nog.Controller.create_node(\r\n    "/World/ROS2Graph/camera_rgb",\r\n    "omni.isaac.ros2_bridge.ROS2CameraHelper"\r\n)\r\n\r\n# Connect nodes\r\nog.Controller.connect(\r\n    "/World/ROS2Graph/ros2_clock.outputs:execOut",\r\n    "/World/ROS2Graph/camera_rgb.inputs:execIn"\r\n)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"headless-training",children:"Headless Training"}),"\n",(0,t.jsx)(n.p,{children:"For reinforcement learning and large-scale training:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# headless_training.py\r\nfrom omni.isaac.kit import SimulationApp\r\n\r\n# Launch in headless mode\r\nconfig = {\r\n    "headless": True,\r\n    "width": 128,\r\n    "height": 128,\r\n}\r\nsimulation_app = SimulationApp(config)\r\n\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nimport torch\r\n\r\n# Setup environment\r\nworld = World(physics_dt=1/120, rendering_dt=1/30)\r\n\r\n# Training loop\r\nnum_episodes = 10000\r\nfor episode in range(num_episodes):\r\n    world.reset()\r\n    \r\n    done = False\r\n    total_reward = 0\r\n    \r\n    while not done:\r\n        # Get observation\r\n        obs = get_observation()\r\n        \r\n        # Policy forward pass\r\n        action = policy(torch.tensor(obs))\r\n        \r\n        # Step simulation\r\n        apply_action(action)\r\n        world.step(render=False)  # No rendering for speed\r\n        \r\n        # Get reward\r\n        reward, done = compute_reward()\r\n        total_reward += reward\r\n    \r\n    # Update policy\r\n    policy.update()\r\n    \r\n    if episode % 100 == 0:\r\n        print(f"Episode {episode}, Reward: {total_reward}")\r\n\r\nsimulation_app.close()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Isaac Sim"})," provides photorealistic simulation with RTX rendering"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"URDF import"})," brings ROS robots into Isaac Sim"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor simulation"})," includes cameras, LiDAR, and IMU with realistic noise"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Replicator"})," automates synthetic data generation with domain randomization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS2 bridge"})," enables seamless integration with the ROS ecosystem"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Headless mode"})," enables large-scale parallel training"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"In the next chapter, we'll explore Vision-Language-Action (VLA) models that can be trained using Isaac Sim's synthetic data capabilities."}),"\n",(0,t.jsx)(n.hr,{}),"\n","\n",(0,t.jsx)(o.A,{episodeUrl:"/podcast/episodes/ep04-isaac-sim",episodeNumber:4,duration:"17 min"})]})}function p(r={}){const{wrapper:n}={...(0,a.R)(),...r.components};return n?(0,t.jsx)(n,{...r,children:(0,t.jsx)(m,{...r})}):m(r)}},5168(r,n,e){e.d(n,{A:()=>h});e(6540);var i=e(8774);const t="container_dCqE",a="card_xNje",o="icon_xPcq",s="content_EpEg",l="label_oX12",d="title_FgAO",c="duration_fnZY",m="button_ldru";var p=e(4848);function h({episodeUrl:r,episodeNumber:n,duration:e}){return(0,p.jsx)("div",{className:t,children:(0,p.jsxs)("div",{className:a,children:[(0,p.jsx)("div",{className:o,children:(0,p.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",fill:"currentColor",children:(0,p.jsx)("path",{d:"M12 1c-4.97 0-9 4.03-9 9v7c0 1.66 1.34 3 3 3h3v-8H5v-2c0-3.87 3.13-7 7-7s7 3.13 7 7v2h-4v8h3c1.66 0 3-1.34 3-3v-7c0-4.97-4.03-9-9-9z"})})}),(0,p.jsxs)("div",{className:s,children:[(0,p.jsx)("span",{className:l,children:"Prefer audio?"}),(0,p.jsxs)("span",{className:d,children:["Listen to Episode ",n]}),(0,p.jsxs)("span",{className:c,children:[e," listen"]})]}),(0,p.jsxs)(i.A,{to:r,className:m,children:[(0,p.jsx)("svg",{viewBox:"0 0 24 24",width:"20",height:"20",fill:"currentColor",children:(0,p.jsx)("path",{d:"M8 5v14l11-7z"})}),"Listen Now"]})]})})}},8453(r,n,e){e.d(n,{R:()=>o,x:()=>s});var i=e(6540);const t={},a=i.createContext(t);function o(r){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof r?r(n):{...n,...r}},[n,r])}function s(r){let n;return n=r.disableParentContext?"function"==typeof r.components?r.components(t):r.components||t:o(r.components),i.createElement(a.Provider,{value:n},r.children)}}}]);